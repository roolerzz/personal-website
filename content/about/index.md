---
title: "About Me"
layout: "single"
hideAuthor: true
---

I'm a Staff Software Engineer with over 12 years of experience building high-performance data platforms and AI-optimized storage systems. My work focuses on solving infrastructure challenges at the intersection of distributed systems and machine learning.

Currently at Crusoe, I'm building S3-compatible object storage with intelligent caching for GPU-intensive ML training. The challenge? Minimizing data access latency to keep expensive GPUs busy and maximize their utilization. I'm working on dual-protocol (NFS/S3) storage interfaces that bridge legacy HPC workflows with modern cloud-native pipelines, along with node-local caching strategies to eliminate storage bottlenecks.

Before Crusoe, I spent several years at AWS working on Amazon Firehose, where I led the architectural migration of Dynamic Partitioning to a microservices architecture. This involved scaling data delivery to support high throughput delivery to S3 across large number of partitions(s3-prefixes). The work required deep optimization of distributed systemsâ€”from rethinking partitioning strategies using Akka Streams to profiling Java services for memory leaks and GC issues.

Earlier at WeWork, I helped migrate Spatial Data Service from PHP to Go/gRPC/Kubernetes, improving latency for a system that served as the source of truth for 800+ global locations. At Wework, I was also involved in building event-driven architecture with Kafka and added comprehensive observability stack.

## What Drives Me

I'm fascinated by the systems challenges in AI infrastructure, particularly around storage. How do you efficiently move massive datasets to hungry GPUs? What's the right caching strategy when your data access patterns across Training or Inference workloads? How do you benchmark storage for such workloads?

I have been learning from  various foundational systems papers such as Dynamo, Spanner, GFS, Raft etc and try to apply those principles to modern ML infrastructure challenges.

I'm actively exploring research and publication opportunities in AI storage systems. If you're working on similar problems, writing papers, or organizing conferences in this space, I'd love to connect and collaborate.

## Technical Interests

- **Languages**: Golang, Java, Python
- **Infrastructure**: Kubernetes, Kafka, Distributed Data Systems especially Databases.
- **DevOps**: CI/CD, Infrastructure as Code, Observability
- **Research/Current Interest Areas**: RDMA storage, GPU cluster optimization, Multi-protocol access patterns

## Education

**B.Tech in Computer Science**
National Institute of Technology, Jalandhar | 2012

## Connect

- Email: [sethi.hemant@gmail.com](mailto:sethi.hemant@gmail.com)
- LinkedIn: [linkedin.com/in/hemantsethi](https://www.linkedin.com/in/hemantsethi/)
- GitHub: [github.com/roolerzz](https://github.com/roolerzz)
- Twitter: [@sethihemant](https://twitter.com/sethihemant)